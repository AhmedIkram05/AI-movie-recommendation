{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System Analysis\n",
    "\n",
    "This notebook analyzes the performance of our recommendation system and explores the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from data_processing import load_data, prepare_data, get_movie_features\n",
    "from recommendation_models import CollaborativeFiltering, ContentBasedFiltering, HybridRecommender\n",
    "from evaluation import evaluate_recommendations, precision_at_k, recall_at_k\n",
    "from visualization import plot_rating_distribution, plot_model_comparison, plot_user_activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ratings, movies = load_data()\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset contains {len(ratings)} ratings from {ratings['userId'].nunique()} users on {ratings['movieId'].nunique()} movies\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore movie data\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='rating', data=ratings)\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze User Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of ratings per user\n",
    "user_counts = ratings.groupby('userId').size().reset_index(name='counts')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(user_counts['counts'], kde=True, bins=30)\n",
    "plt.title('Distribution of Ratings per User')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Count of Users')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average ratings per user: {user_counts['counts'].mean():.2f}\")\n",
    "print(f\"Median ratings per user: {user_counts['counts'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most popular movies\n",
    "movie_counts = ratings.groupby('movieId').size().reset_index(name='counts')\n",
    "top_movies = movie_counts.merge(movies[['movieId', 'title']], on='movieId').sort_values('counts', ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='counts', y='title', data=top_movies)\n",
    "plt.title('Top 20 Most Rated Movies')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Movie Title')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare Recommendation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "user_item_matrix, train_data, test_data = prepare_data(ratings)\n",
    "movie_features = get_movie_features(movies)\n",
    "\n",
    "# Load pre-trained models if available, otherwise train new ones\n",
    "try:\n",
    "    with open('models/cf_model.pkl', 'rb') as f:\n",
    "        cf_model = pickle.load(f)\n",
    "    with open('models/hybrid_model.pkl', 'rb') as f:\n",
    "        hybrid_model = pickle.load(f)\n",
    "    print(\"Loaded pre-trained models\")\n",
    "except:\n",
    "    print(\"Training new models\")\n",
    "    cf_model = CollaborativeFiltering(k=20)\n",
    "    cf_model.fit(user_item_matrix)\n",
    "    \n",
    "    hybrid_model = HybridRecommender(cf_weight=0.7)\n",
    "    hybrid_model.fit(user_item_matrix, movie_features, movies, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models on a set of random users\n",
    "test_users = np.random.choice(test_data['userId'].unique(), 5, replace=False)\n",
    "\n",
    "for user_id in test_users:\n",
    "    print(f\"\\nRecommendations for User {user_id}:\")\n",
    "    \n",
    "    # Get CF recommendations\n",
    "    cf_recs = cf_model.recommend_items(user_id, n_recommendations=5)\n",
    "    if not cf_recs.empty:\n",
    "        cf_recs = cf_recs.merge(movies[['movieId', 'title']], on='movieId')\n",
    "        print(\"\\nCollaborative filtering recommendations:\")\n",
    "        for _, row in cf_recs.iterrows():\n",
    "            print(f\"- {row['title']} (score: {row['score']:.2f})\")\n",
    "    \n",
    "    # Get Hybrid recommendations\n",
    "    hybrid_recs = hybrid_model.recommend_items(user_id, n_recommendations=5)\n",
    "    if not hybrid_recs.empty:\n",
    "        hybrid_recs = hybrid_recs.merge(movies[['movieId', 'title']], on='movieId')\n",
    "        print(\"\\nHybrid recommendations:\")\n",
    "        for _, row in hybrid_recs.iterrows():\n",
    "            print(f\"- {row['title']} (score: {row['score']:.2f})\")\n",
    "        \n",
    "    # Get actual movies the user liked in test set\n",
    "    user_test = test_data[test_data['userId'] == user_id]\n",
    "    if not user_test.empty:\n",
    "        liked_movies = user_test[user_test['rating'] >= 4]['movieId'].tolist()\n",
    "        if liked_movies:\n",
    "            liked_titles = movies[movies['movieId'].isin(liked_movies)]['title'].tolist()\n",
    "            print(\"\\nActually liked movies in test set:\")\n",
    "            for title in liked_titles[:5]:\n",
    "                print(f\"- {title}\")\n",
    "    \n",
    "    print(\"---\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models more formally\n",
    "print(\"Evaluating collaborative filtering model...\")\n",
    "cf_precision, cf_recall, cf_hit_rate = evaluate_recommendations(\n",
    "    cf_model, test_data, movies, k=10, verbose=False\n",
    ")\n",
    "\n",
    "print(\"Evaluating hybrid model...\")\n",
    "hybrid_precision, hybrid_recall, hybrid_hit_rate = evaluate_recommendations(\n",
    "    hybrid_model, test_data, movies, k=10, verbose=False\n",
    ")\n",
    "\n",
    "# Create visualization of results\n",
    "metrics = {\n",
    "    'Collaborative': [cf_precision, cf_recall, cf_hit_rate],\n",
    "    'Hybrid': [hybrid_precision, hybrid_recall, hybrid_hit_rate]\n",
    "}\n",
    "\n",
    "# Create bar chart comparing the models\n",
    "metrics_df = pd.DataFrame(metrics, index=['Precision@10', 'Recall@10', 'Hit Rate'])\n",
    "metrics_df.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Comparison of Recommendation Models')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Model')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Collaborative Filtering: Precision@10={cf_precision:.4f}, Recall@10={cf_recall:.4f}, Hit Rate={cf_hit_rate:.4f}\")\n",
    "print(f\"Hybrid Model: Precision@10={hybrid_precision:.4f}, Recall@10={hybrid_recall:.4f}, Hit Rate={hybrid_hit_rate:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
